# BI-Agentì˜ Blocking Calls ì™„ì „ ë¶„ì„

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° ë° ì£¼ìš” íŒŒì¼

```
/Users/zokr/python_workspace/BI-Agent/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/data_source/
â”‚   â”‚   â”œâ”€â”€ profiler.py                    âš ï¸ ë™ê¸°, ëŒ€ìš©ëŸ‰ì—ì„œ ëŠë¦¼
â”‚   â”‚   â”œâ”€â”€ connection_manager.py          âš ï¸ run_query()ëŠ” BLOCKING
â”‚   â”‚   â”œâ”€â”€ metadata_scanner.py            âš ï¸ scan_table()ì€ BLOCKING (í”„ë¡œíŒŒì¼ë§)
â”‚   â”‚   â”œâ”€â”€ table_recommender.py           âœ… async def ìˆìŒ
â”‚   â”‚   â”œâ”€â”€ sql_generator.py               âœ… async def ìˆìŒ
â”‚   â”‚   â”œâ”€â”€ query_healer.py                âœ… async def ìˆìŒ
â”‚   â”‚   â”œâ”€â”€ pandas_generator.py            âœ… async def ìˆìŒ
â”‚   â”‚   â”œâ”€â”€ data_source_agent.py           âœ… async def ìˆìŒ
â”‚   â”‚   â””â”€â”€ mcp_client.py                  âœ… async def ìˆìŒ
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â”œâ”€â”€ bi_agent_console.py            âœ… Textual App (async/await ì§€ì›)
â”‚   â”‚   â”œâ”€â”€ orchestrators/
â”‚   â”‚   â”‚   â””â”€â”€ agentic_orchestrator.py    âš ï¸ ToolRegistry ë„êµ¬ê°€ ë™ê¸°
â”‚   â”‚   â””â”€â”€ screens/
â”‚   â”‚       â””â”€â”€ database_explorer_screen.py âœ… run_in_executor ì‚¬ìš©
â”‚   â”‚
â”‚   â””â”€â”€ main.py                            âœ… asyncio.run() ì‚¬ìš©
```

---

## ğŸ”´ BLOCKING CALL ìƒì„¸ ë¶„ì„

### 1. profiler.py - DataProfiler

#### ìœ„ì¹˜
```
/Users/zokr/python_workspace/BI-Agent/backend/agents/data_source/profiler.py
```

#### ë¬¸ì œ ì½”ë“œ
```python
def profile(self) -> Dict[str, Any]:
    """Performs full profiling of the loaded DataFrame"""
    if self.df is None:
        raise ValueError("No data loaded to profile.")

    column_details = self._get_column_details()  # âš ï¸ O(n*m) - BLOCKING
    overall_quality = self._calculate_overall_quality_score(column_details)

    return {
        "overview": self._get_overview(),
        "columns": column_details,
        "overall_quality_score": overall_quality,
        "sample": self.df.head(5).to_dict(orient='records')
    }

def _get_column_details(self) -> List[Dict[str, Any]]:
    """Analyzes each column in detail with enhanced statistics"""
    column_info = []

    for col in self.df.columns:  # âš ï¸ ê° ì»¬ëŸ¼ë§ˆë‹¤...
        series = self.df[col]

        # ìˆ˜ì¹˜í˜•
        if col_type == "numerical":
            clean_series = series.dropna()
            details.update({
                "mean": round(float(clean_series.mean()), 4),        # âš ï¸ O(n)
                "std": round(float(clean_series.std()), 4),          # âš ï¸ O(n)
                "min": float(clean_series.min()),                    # âš ï¸ O(n)
                "max": float(clean_series.max()),                    # âš ï¸ O(n)
                "median": float(clean_series.median()),              # âš ï¸ O(n)
                "q25": float(clean_series.quantile(0.25)),           # âš ï¸ O(n)
                "q50": float(clean_series.quantile(0.50)),           # âš ï¸ O(n)
                "q75": float(clean_series.quantile(0.75)),           # âš ï¸ O(n)
                "distribution": self._get_distribution(clean_series) # âš ï¸ O(n)
            })
        # ë²”ì£¼í˜•
        elif col_type == "categorical":
            details.update({
                "top_values": series.value_counts().head(5).to_dict(),  # âš ï¸ O(n)
                "distribution": self._get_categorical_distribution(series) # âš ï¸ O(n)
            })
```

#### ì„±ëŠ¥ ë¶„ì„
```
1Mí–‰ Ã— 50ì»¬ëŸ¼ ë°ì´í„°:
- ê° ì»¬ëŸ¼: 9ê°œ ì‘ì—… Ã— O(n) = ~9M ì—°ì‚°
- 50ê°œ ì»¬ëŸ¼: 50 Ã— 9M = 450M ì—°ì‚°
- ì˜ˆìƒ ì‹œê°„: 1-2ì´ˆ

ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹!
```

#### ì‚¬ìš©ì²˜
```python
# metadata_scanner.py
def scan_table(self, conn_id: str, table_name: str) -> Dict[str, Any]:
    df = self.conn_mgr.run_query(conn_id, query)  # 100ms

    profiler = DataProfiler(df)
    profile_data = profiler.profile()  # âš ï¸ 1-2ì´ˆ ë¸”ë¡œí‚¹!

    return { ... }
```

---

### 2. connection_manager.py - ConnectionManager

#### ìœ„ì¹˜
```
/Users/zokr/python_workspace/BI-Agent/backend/agents/data_source/connection_manager.py
```

#### ë¬¸ì œ ì½”ë“œ 1: run_query()
```python
def run_query(self, conn_id: str, query: str) -> pd.DataFrame:
    """Runs a SQL query with robust error handling and monitoring."""
    try:
        session = self.get_connection(conn_id)

        start_time = datetime.datetime.now()
        if conn_type in ["sqlite", "postgres", "mysql", "duckdb"]:
            from sqlalchemy import text
            if hasattr(session, 'connect'):
                with session.connect() as conn:
                    df = pd.read_sql_query(text(query), conn)  # âš ï¸ BLOCKING I/O!
            else:
                df = pd.read_sql_query(query, session)  # âš ï¸ BLOCKING I/O!
        elif conn_type == "excel":
            df = pd.read_excel(session)  # âš ï¸ BLOCKING I/O!

        end_time = datetime.datetime.now()
        duration = (end_time - start_time).total_seconds()
        logger.info(f"Query executed on {conn_id} in {duration:.4f}s. Rows: {len(df)}")
        return df
    except Exception as e:
        logger.error(f"Query failed on {conn_id}: {e}")
        raise RuntimeError(f"Query execution failed: {e}")
```

**ë¬¸ì œì **:
- `pd.read_sql_query()`: ë„¤íŠ¸ì›Œí¬ I/O (PostgreSQL, MySQL) ë˜ëŠ” íŒŒì¼ I/O (SQLite)
- ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹
- ëŒ€ìš©ëŸ‰ ê²°ê³¼ì…‹ì€ ìˆ˜ ì´ˆ ëŒ€ê¸°

#### ë¬¸ì œ ì½”ë“œ 2: register_connection()
```python
def register_connection(self, conn_id: str, conn_type: str, config: Dict[str, Any], ...):
    # SSH í„°ë„ë§ ì„¤ì • í™•ì¸
    ssh_config = config.get('ssh', None)

    # Test connection before registration - Apply env vars for testing
    logger.info(f"Testing connection before registering '{conn_id}'...")
    test_config = self._inject_env_vars(config.copy())
    test_ssh_config = self._inject_env_vars(ssh_config.copy()) if ssh_config else None

    test_result = test_connection(conn_type, test_config, test_ssh_config)  # âš ï¸ BLOCKING!

    if not test_result.success:
        error_msg = f"Connection test failed: {test_result.error_message}"
        raise RuntimeError(...)
```

**test_connection() ë¶„ì„**:
```python
# connection_validator.py
def test_connection(conn_type: str, config: Dict[str, Any], ssh_config: Optional[Dict] = None):
    try:
        if conn_type == "sqlite":
            conn = sqlite3.connect(config["path"])  # âš ï¸ íŒŒì¼ I/O
            cur = conn.cursor()
            cur.execute("SELECT 1")  # âš ï¸ BLOCKING!
            cur.fetchone()
            conn.close()
        elif conn_type == "postgres":
            # psycopg2 ì—°ê²°
            conn = psycopg2.connect(
                host=config["host"],      # âš ï¸ ë„¤íŠ¸ì›Œí¬ I/O (3-5ì´ˆ)
                port=config["port"],
                database=config["dbname"],
                user=config["user"],
                password=config["password"]
            )
            cur = conn.cursor()
            cur.execute("SELECT 1")      # âš ï¸ ë„¤íŠ¸ì›Œí¬ I/O
            cur.fetchone()
            conn.close()
        # ... ê¸°íƒ€ db íƒ€ì… ...
```

#### ì„±ëŠ¥ ë¶„ì„
```
SQLite:        ~100ms (ë¡œì»¬ íŒŒì¼ I/O)
PostgreSQL:    ~3-5s  (ë„¤íŠ¸ì›Œí¬ ì™•ë³µ)
MySQL:         ~3-5s  (ë„¤íŠ¸ì›Œí¬ ì™•ë³µ)
Snowflake:     ~5-10s (í´ë¼ìš°ë“œ ì—°ê²°)
```

#### ì‚¬ìš©ì²˜ (ë©”ì¸ ìŠ¤ë ˆë“œ)
```python
# bi_agent_console.py
async def _run_explore(self, query: Optional[str], ...):
    # Sync connection from Orchestrator CM â†’ Agent CM
    orch_conn = self.conn_mgr.get_connection(conn_id)
    if orch_conn:
        self.agent_conn_mgr.register_connection(
            conn_id=conn_id,
            conn_type=conn_type,
            config=conn_config.copy(),
            ...
        )  # âš ï¸ test_connection() í˜¸ì¶œ (3-10ì´ˆ ëŒ€ê¸°!)
```

---

### 3. metadata_scanner.py - MetadataScanner

#### ìœ„ì¹˜
```
/Users/zokr/python_workspace/BI-Agent/backend/agents/data_source/metadata_scanner.py
```

#### ë¬¸ì œ ì½”ë“œ 1: scan_source()
```python
def scan_source(self, conn_id: str, deep_scan: bool = False) -> Dict[str, Any]:
    """Scans the source."""
    conn_info = self._get_conn_info(conn_id)
    conn_type = conn_info["type"]

    metadata = {
        "conn_id": conn_id,
        "type": conn_type,
        "tables": []
    }

    table_names = self._list_tables(conn_id, conn_type)  # âš ï¸ BLOCKING!

    for table in table_names:  # âš ï¸ Nê°œ í…Œì´ë¸”ë§ˆë‹¤...
        if deep_scan:
            table_meta = self.scan_table(conn_id, table)  # âš ï¸ BLOCKING! (1.1ì´ˆ/í…Œì´ë¸”)
        else:
            table_meta = {"table_name": table, "is_lazy": True}
        metadata["tables"].append(table_meta)

    return metadata
```

#### ë¬¸ì œ ì½”ë“œ 2: scan_table()
```python
def scan_table(self, conn_id: str, table_name: str) -> Dict[str, Any]:
    """Performs detailed profiling of a single table."""
    # 1. Fetch Sample Data
    safe_table_name = table_name.replace('"', '""')
    query = f'SELECT * FROM "{safe_table_name}" LIMIT 100'
    df = self.conn_mgr.run_query(conn_id, query)  # âš ï¸ 100ms BLOCKING

    # 2. Use DataProfiler for statistical summary
    profiler = DataProfiler(df)
    profile_data = profiler.profile()  # âš ï¸ 1-2ì´ˆ BLOCKING! (50ì»¬ëŸ¼ ê¸°ì¤€)

    return {
        "table_name": table_name,
        "row_count_estimate": profile_data["overview"]["rows"],
        "columns": profile_data["columns"],
        "sample": profile_data["sample"]
    }
```

#### ë¬¸ì œ ì½”ë“œ 3: _list_tables()
```python
def _list_tables(self, conn_id: str, conn_type: str) -> List[str]:
    """Lists table names based on connection type."""
    logger.info(f"Listing tables for connection '{conn_id}' (type: {conn_type})")
    try:
        if conn_type == "sqlite":
            query = "SELECT name FROM sqlite_master WHERE type='table'"
            df = self.conn_mgr.run_query(conn_id, query)  # âš ï¸ BLOCKING! (50ms)
            tables = df["name"].tolist()
        elif conn_type == "postgres":
            query = "SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'"
            df = self.conn_mgr.run_query(conn_id, query)  # âš ï¸ BLOCKING! (100-500ms)
            tables = df["table_name"].tolist()
        # ...
        return tables
```

#### ì„±ëŠ¥ ë¶„ì„
```
Deep scan (50ê°œ í…Œì´ë¸”):

1. _list_tables():        50ms
2. ê° í…Œì´ë¸” (Ã—50):
   - run_query(LIMIT 100): 100ms/í…Œì´ë¸”
   - profile():            1-2ì´ˆ/í…Œì´ë¸”
   = 1.1-1.2ì´ˆ/í…Œì´ë¸”
3. ì´: 50 Ã— 1.1s = 55ì´ˆ

Shallow scan (50ê°œ í…Œì´ë¸”):
1. _list_tables():        50ms
2. ë©”íƒ€ë°ì´í„° ì¡°íšŒ:       0ms (is_lazy=True)
ì´: 50ms âœ…
```

#### ì‚¬ìš©ì²˜ (DatabaseExplorerScreen)
```python
# database_explorer_screen.py
async def _load_schema(self):
    def _scan_metadata():
        scanner = MetadataScanner(self.agent_conn_mgr)
        return scanner.scan_source(self.connection_id, deep_scan=False)  # âœ… shallow

    loop = asyncio.get_event_loop()
    metadata = await loop.run_in_executor(None, _scan_metadata)  # âœ… ìŠ¤ë ˆë“œ í’€ ì‚¬ìš©!
```

---

### 4. agentic_orchestrator.py - ToolRegistry

#### ìœ„ì¹˜
```
/Users/zokr/python_workspace/BI-Agent/backend/orchestrator/orchestrators/agentic_orchestrator.py
```

#### ë¬¸ì œ ì½”ë“œ 1: query_database()
```python
def query_database(query_description: str = "") -> str:
    """ìì—°ì–´ ì„¤ëª… ë˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    import sqlite3
    import os

    db_path = os.path.join(...)

    query = query_description.strip()
    if not query.upper().startswith("SELECT"):
        query = "SELECT * FROM sales_performance LIMIT 20"

    try:
        conn = sqlite3.connect(db_path)  # âš ï¸ I/O
        conn.row_factory = sqlite3.Row
        cur = conn.cursor()
        cur.execute(query)  # âš ï¸ BLOCKING!
        rows = cur.fetchall()  # âš ï¸ I/O
        columns = [desc[0] for desc in cur.description] if cur.description else []
        conn.close()

        if not rows:
            return f"[ë°ì´í„° ì¡°íšŒ] ê²°ê³¼ ì—†ìŒ (SQL: {query})"

        result = f"[ë°ì´í„° ì¡°íšŒ] {len(rows)}ê±´ ë°˜í™˜\n"
        # í¬ë§·íŒ…...
        return result
    except Exception as e:
        return f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"
```

**ë¬¸ì œì **:
- sqlite3.connect() â†’ DB íŒŒì¼ I/O
- cur.execute() â†’ SQL ì‹¤í–‰ (ë„¤íŠ¸ì›Œí¬ ì—†ìŒ, ë¡œì»¬ì´ì§€ë§Œ ì—¬ì „íˆ I/O)
- cur.fetchall() â†’ ë°ì´í„° ë¡œë“œ ë° ì§ë ¬í™”

#### ë¬¸ì œ ì½”ë“œ 2: analyze_schema()
```python
def analyze_schema(table_name: str = "") -> str:
    """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        conn = sqlite3.connect(db_path)  # âš ï¸ I/O
        cur = conn.cursor()

        # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        tables = cur.execute(
            "SELECT name FROM sqlite_master WHERE type='table'"
        ).fetchall()  # âš ï¸ BLOCKING! (50ms)
        table_list = [t[0] for t in tables]

        for tbl in targets:
            # ì»¬ëŸ¼ ì •ë³´
            cols = cur.execute(f'PRAGMA table_info("{tbl}")').fetchall()  # âš ï¸ BLOCKING! (10ms/tbl)

            # í–‰ ê°œìˆ˜
            count = cur.execute(f'SELECT COUNT(*) FROM "{tbl}"').fetchone()[0]  # âš ï¸ BLOCKING! (O(n))

            result += f"\nğŸ“Š {tbl} ({count}í–‰)\n"

            profile_data = []
            for c in cols:
                # ìœ ë‹ˆí¬ ê°’ ì¹´ìš´íŠ¸
                unique = cur.execute(
                    f'SELECT COUNT(DISTINCT "{col_name}") FROM "{tbl}"'
                ).fetchone()[0]  # âš ï¸ BLOCKING! (O(n))
```

**ì„±ëŠ¥ ë¶„ì„**:
```
analyze_schema() for 5 tables:
1. _list_tables():        50ms
2. ê° í…Œì´ë¸” (Ã—5):
   - PRAGMA table_info():  10ms
   - COUNT(*):             1-5ì´ˆ(í…Œì´ë¸” í¬ê¸°ì— ë”°ë¼)
   - COUNT(DISTINCT col):  1-5ì´ˆ/ì»¬ëŸ¼
3. ì´: 50ms + 5Ã—(10ms + 2-10ì´ˆ) = ì•½ 15-60ì´ˆ!
```

#### ì‚¬ìš©ì²˜ (ReAct ë£¨í”„)
```python
# bi_agent_console.py
async def process_query(self, query: str) -> None:
    try:
        orchestrator = self._get_orchestrator()

        # âš ï¸ orchestrator.run()ì´ ToolRegistry.execute()ë¥¼ í˜¸ì¶œ
        result = await orchestrator.run(query, context={
            "active_connection": getattr(self, '_active_conn_id', None),
        })
        # orchestrator ë‚´ë¶€ì—ì„œ:
        # â†’ ReAct ë£¨í”„ â†’ ToolRegistry.execute("query_database", ...)
        # â†’ ìœ„ì˜ query_database() í•¨ìˆ˜ ì‹¤í–‰ (ë™ê¸°, BLOCKING!)
```

---

## ğŸ“‹ ì „ì²´ Blocking Call ìš”ì•½í‘œ

| íŒŒì¼ | í•¨ìˆ˜ | ì‘ì—… | ì‹œê°„ | UI ë¸”ë¡œí‚¹ | í•´ê²°ì±… |
|------|------|------|------|---------|--------|
| profiler.py | `profile()` | ì»¬ëŸ¼ ë¶„ì„ | 1-2ì´ˆ | âš ï¸ ì˜ˆ | `run_in_executor` |
| connection_manager.py | `run_query()` | SQL ì‹¤í–‰ | 100ms-10s | âš ï¸ ì˜ˆ | `run_in_executor` |
| connection_manager.py | `register_connection()` | ì—°ê²° í…ŒìŠ¤íŠ¸ | 3-10s | âš ï¸ ì˜ˆ | `run_in_executor` |
| metadata_scanner.py | `scan_source(deep)` | Nê°œ í…Œì´ë¸” ìŠ¤ìº” | 50ì´ˆ+ | âš ï¸ ì˜ˆ | async + ë³‘ë ¬ |
| metadata_scanner.py | `scan_table()` | 1ê°œ í…Œì´ë¸” ë¶„ì„ | 1-2ì´ˆ | âš ï¸ ì˜ˆ | `run_in_executor` |
| metadata_scanner.py | `_list_tables()` | í…Œì´ë¸” ëª©ë¡ | 50-500ms | âš ï¸ ì˜ˆ | `run_in_executor` |
| agentic_orchestrator.py | `query_database()` | SQLite ì¿¼ë¦¬ | 100ms-5s | âš ï¸ ì˜ˆ | async ë„êµ¬ |
| agentic_orchestrator.py | `analyze_schema()` | ìŠ¤í‚¤ë§ˆ ë¶„ì„ | 15-60ì´ˆ | âš ï¸ ì˜ˆ | async ë„êµ¬ + ë³‘ë ¬ |

---

## âœ… ì´ë¯¸ ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ëœ ë¶€ë¶„

### DatabaseExplorerScreen - ì˜¬ë°”ë¥¸ ì‚¬ìš© ì˜ˆ

```python
# database_explorer_screen.py (ë¼ì¸ 305-343)
async def _load_schema(self):
    """Loads tables/views from the connection manager asynchronously."""
    tree = self.query_one("#schema-tree")

    loading_node = tree.root.add("ğŸ“¡ Loading schema...", expand=True)

    try:
        # âœ… ë™ê¸° í•¨ìˆ˜ë¥¼ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
        def _scan_metadata():
            scanner = MetadataScanner(self.agent_conn_mgr)
            return scanner.scan_source(self.connection_id, deep_scan=False)

        # âœ… executorë¡œ ê°ì‹¸ê¸° (ë©”ì¸ ìŠ¤ë ˆë“œ ë¸”ë¡œí‚¹ ì•ˆ í•¨)
        loop = asyncio.get_event_loop()
        metadata = await loop.run_in_executor(None, _scan_metadata)

        # UI ì—…ë°ì´íŠ¸ (ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ)
        tree.root.remove_children()
        tables_node = tree.root.add("ğŸ“Š Tables", expand=True)

        for table_info in metadata.get("tables", []):
            table_name = table_info.get("table_name", "unknown")
            tables_node.add_leaf(f"  {table_name}")
```

### BI_AgentConsole - ì˜¬ë°”ë¥¸ ë¹„ë™ê¸° ë©”ì„œë“œë“¤

```python
# bi_agent_console.py
async def on_input_submitted(self, event: Input.Submitted) -> None:
    """âœ… async defë¡œ ì˜¬ë°”ë¥´ê²Œ ì„ ì–¸"""
    user_text = event.value.strip()

    if self.flow_engine.is_active():
        consumed = await self.flow_engine.handle_input(user_text)  # âœ… await
        if consumed:
            return

    if user_text.startswith("/"):
        await self.handle_command(user_text)  # âœ… await
    else:
        await self.process_query(user_text)  # âœ… await

async def process_query(self, query: str) -> None:
    """âœ… async defë¡œ ë©”ì¸ ì¿¼ë¦¬ ì²˜ë¦¬"""
    # Thinking í‘œì‹œ
    thinking = ThinkingPanel()
    chat_log.mount(thinking)

    try:
        orchestrator = self._get_orchestrator()
        # âœ… awaitë¡œ ReAct ë£¨í”„ ì‹¤í–‰
        result = await orchestrator.run(query, context={...})

        # UI ì—…ë°ì´íŠ¸
        chat_log.mount(MessageBubble(...))
    finally:
        # ì •ë¦¬
        pass
```

---

## ğŸš€ ê°œì„  ì˜ˆìƒ íš¨ê³¼

### í˜„ì¬ ìƒíƒœ (Blocking)

```
ì‚¬ìš©ì ì…ë ¥ "50ê°œ í…Œì´ë¸” ë¶„ì„" (deep_scan=True)
    â†“
process_query() í˜¸ì¶œ
    â†“
orchestrator.run() í˜¸ì¶œ (async)
    â†“
query ë„êµ¬ ì‹¤í–‰ (ë™ê¸°!)
    â†“
metadata_scanner.scan_source(deep=True)  â† BLOCKING 50ì´ˆ
    â†“
UI ì™„ì „íˆ í”„ë¦¬ì§• ğŸ”´
```

### ê°œì„  í›„ (Async + ë³‘ë ¬)

```
ì‚¬ìš©ì ì…ë ¥ "50ê°œ í…Œì´ë¸” ë¶„ì„" (deep_scan=True)
    â†“
process_query() í˜¸ì¶œ
    â†“
orchestrator.run() í˜¸ì¶œ (async)
    â†“
query ë„êµ¬ ì‹¤í–‰ (async!)
    â†“
asyncio.gather(*5ê°œ í…Œì´ë¸” ë³‘ë ¬) â† 11ì´ˆ
    â†“
UI ë°˜ì‘ ê°€ëŠ¥ ğŸŸ¢

ì‚¬ìš©ìëŠ” ë™ì‹œì—:
- ë‹¤ë¥¸ ì¿¼ë¦¬ ì…ë ¥ ê°€ëŠ¥
- UI ìŠ¤í¬ë¡¤ ê°€ëŠ¥
- í™”ë©´ ì—…ë°ì´íŠ¸ ë³´ì„
```

---

## ğŸ“Œ í•µì‹¬ ê²°ë¡ 

### 1. ê°€ì¥ ì‹¬ê°í•œ Blocking Call

1. **metadata_scanner.scan_source(deep=True)**: 50ì´ˆ+
2. **agentic_orchestrator.analyze_schema()**: 15-60ì´ˆ
3. **connection_manager.run_query()**: ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° (ìˆ˜ ì´ˆ)
4. **profiler.profile()**: 1-2ì´ˆ

### 2. í˜„ì¬ ìƒí™©

- **DatabaseExplorerScreen**: âœ… ì˜¬ë°”ë¥´ê²Œ êµ¬í˜„ (run_in_executor ì‚¬ìš©)
- **bi_agent_console**: âœ… async ì˜ êµ¬í˜„
- **MetadataScanner**: âš ï¸ ë™ê¸°, ë³‘ë ¬í™” í•„ìš”
- **AgenticOrchestrator**: âš ï¸ ë„êµ¬ê°€ ë™ê¸°

### 3. ìš°ì„  ê°œì„  ìˆœì„œ

1. **MetadataScannerë¥¼ asyncë¡œ ë¦¬íŒ©í† ë§** â†’ 50ì´ˆ â†’ 11ì´ˆ (5ë°°)
2. **ToolRegistry ë„êµ¬ë¥¼ asyncë¡œ ë³€ê²½** â†’ UI ë°˜ì‘ì„± í–¥ìƒ
3. **ProfileCache ì¶”ê°€** â†’ ë°˜ë³µ ìš”ì²­ ë¹ ë¥´ê²Œ

### 4. ê¸°ëŒ€ íš¨ê³¼

- 50ê°œ í…Œì´ë¸” deep scan: **55ì´ˆ â†’ 11ì´ˆ** (5ë°° ê°œì„ )
- ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬: **UI í”„ë¦¬ì§• ì œê±°**
- ì‚¬ìš©ì ê²½í—˜: **ë§¤ìš° í–¥ìƒ**

