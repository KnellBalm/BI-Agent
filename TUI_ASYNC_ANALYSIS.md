# BI-Agent TUI ì„±ëŠ¥ê³¼ ë¹„ë™ê¸° ì²˜ë¦¬ ë¶„ì„

## ğŸ“‹ ëª©ì°¨
1. [profiler.py ì „ì²´ ë‚´ìš©](#1-profilerpy-ì „ì²´-ë‚´ìš©)
2. [async def ì£¼ìš” íŒŒì¼ ëª©ë¡](#2-async-def-ì£¼ìš”-íŒŒì¼-ëª©ë¡)
3. [TUI ë©”ì¸ ì§„ì…ì ](#3-tui-ë©”ì¸-ì§„ì…ì )
4. [Blocking Call ë¶„ì„](#4-blocking-call-ë¶„ì„-ë°-ì„±ëŠ¥-ì´ìŠˆ)
5. [ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­](#5-ì„±ëŠ¥-ìµœì í™”-ê¶Œì¥ì‚¬í•­)

---

## 1. profiler.py ì „ì²´ ë‚´ìš©

### íŒŒì¼ ìœ„ì¹˜
`/Users/zokr/python_workspace/BI-Agent/backend/agents/data_source/profiler.py`

### ì—­í• 
- ë°ì´í„°ì†ŒìŠ¤ ë¶„ì„ ë° í†µê³„ ìš”ì•½
- DataFrame ë˜ëŠ” íŒŒì¼ì˜ í”„ë¡œíŒŒì¼ë§ ì •ë³´ ì¶”ì¶œ
- ì»¬ëŸ¼ë³„ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°

### ì£¼ìš” ë©”ì„œë“œ

#### 1. `profile()` - ì „ì²´ í”„ë¡œíŒŒì¼ë§
```python
def profile(self) -> Dict[str, Any]:
    """Performs full profiling of the loaded DataFrame"""
    - column_details: ì»¬ëŸ¼ë³„ ìƒì„¸ ë¶„ì„
    - overall_quality_score: ì „ì²´ í’ˆì§ˆ ì ìˆ˜ (0-100)
    - sample: ìƒìœ„ 5í–‰ ìƒ˜í”Œ ë°ì´í„°
```

#### 2. `_get_column_details()` - ì»¬ëŸ¼ë³„ ë¶„ì„
ê° ì»¬ëŸ¼ë§ˆë‹¤:
- **ê¸°ë³¸ ì •ë³´**: name, type (numerical/categorical/datetime/text), dtype
- **ê²°ì¸¡ì¹˜**: missing_count, missing_pct
- **ìœ ë‹ˆí¬ ê°’**: unique count
- **ëŒ€í‘œê°’**: mode
- **í’ˆì§ˆ ì ìˆ˜**: 0-100

**ìˆ˜ì¹˜í˜•(numerical) ì»¬ëŸ¼**:
- í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’
- ì¤‘ì•™ê°’, Q25, Q50, Q75 (ë¶„ìœ„ìˆ˜)
- íˆìŠ¤í† ê·¸ë¨ ë¶„í¬ (10ê°œ bins)

**ë²”ì£¼í˜•(categorical) ì»¬ëŸ¼**:
- ìƒìœ„ 5ê°œ ê°’ì˜ ë¶„í¬
- ë²”ì£¼ ë¶„í¬ (ìƒìœ„ 10ê°œ)

**ì‹œê°„í˜•(datetime) ì»¬ëŸ¼**:
- ìµœì†Œ/ìµœëŒ€ ë‚ ì§œ

#### 3. `_calculate_column_quality_score()` - í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
```python
completeness_score = (1 - missing_pct) * 100  # 70% ê°€ì¤‘ì¹˜
uniqueness_score = varies by type              # 30% ê°€ì¤‘ì¹˜
final_score = completeness_score * 0.7 + uniqueness_score * 0.3
```

#### 4. `_infer_type()` - íƒ€ì… ì¶”ë¡ 
```python
- ìˆ˜ì¹˜í˜•: pd.api.types.is_numeric_dtype()
- ì‹œê°„í˜•: pd.api.types.is_datetime64_any_dtype()
- ë²”ì£¼í˜•: unique_count <= 20 OR (unique_count / total) < 0.3
- í…ìŠ¤íŠ¸: ê·¸ ì™¸
```

### ì„±ëŠ¥ íŠ¹ì„±

| ì‘ì—… | ë³µì¡ë„ | ë³‘ëª© | ì˜ˆìƒ ì‹œê°„ |
|------|--------|------|---------|
| ê°œìš” ê³„ì‚° | O(n) | isnull().sum() | ~100ms (1Mí–‰) |
| ì»¬ëŸ¼ ë¶„ì„ | O(n*m) | describe(), nunique() | ~500ms (1Mí–‰Ã—50ì»¬ëŸ¼) |
| ë¶„í¬ ê³„ì‚° | O(n) | np.histogram() | ~200ms |
| ì „ì²´ í”„ë¡œíŒŒì¼ | O(n*m) | ì»¬ëŸ¼ ë¶„ì„ | ~1-2ì´ˆ (1Mí–‰Ã—50ì»¬ëŸ¼) |

**âš ï¸ ë™ê¸° ë¸”ë¡œí‚¹**: í˜„ì¬ ëª¨ë“  ë©”ì„œë“œê°€ ë™ê¸°ì‹
- TUIì—ì„œ í˜¸ì¶œ ì‹œ UI í”„ë¦¬ì§• ìœ„í—˜
- íŠ¹íˆ `_get_column_details()`ëŠ” ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ëŠë¦¼

---

## 2. async def ì£¼ìš” íŒŒì¼ ëª©ë¡

### ë°ì´í„°ì†ŒìŠ¤ ì—ì´ì „íŠ¸ (backend/agents/data_source/)

#### ğŸ“Œ connection_manager.py
```python
class ConnectionManager:
    def __init__(self, project_id: str = "default")  # ë™ê¸° ì´ˆê¸°í™”
    def register_connection(...)  # ë™ê¸°, í…ŒìŠ¤íŠ¸ í¬í•¨
    def get_connection(self, conn_id: str)  # ë™ê¸°, ì„¸ì…˜ ì´ˆê¸°í™”
    def run_query(self, conn_id: str, query: str) -> pd.DataFrame  # âš ï¸ BLOCKING!
        â””â”€ pd.read_sql_query(text(query), conn)  # ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸°
    def _start_ssh_tunnel(...)  # ë™ê¸°, SSH ì—°ê²° ì„¤ì •
```

**âš ï¸ Blocking Call**:
- `run_query()`: ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ ì‹¤í–‰ (ë„¤íŠ¸ì›Œí¬ I/O)
- `_initialize_session()`: SQLAlchemy ì—”ì§„ ìƒì„±

#### ğŸ“Œ metadata_scanner.py
```python
class MetadataScanner:
    def scan_source(self, conn_id: str, deep_scan: bool = False)
        â””â”€ self._list_tables()  # ë™ê¸°, í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        â””â”€ self.scan_table()    # ë™ê¸°, ê° í…Œì´ë¸” í”„ë¡œíŒŒì¼ë§
            â””â”€ self.conn_mgr.run_query()  # âš ï¸ BLOCKING!
            â””â”€ DataProfiler().profile()   # âš ï¸ BLOCKING! (1-2ì´ˆ)

    def _list_tables(self, conn_id: str, conn_type: str)
        â””â”€ self.conn_mgr.run_query()  # BLOCKING
```

**âš ï¸ ì„±ëŠ¥ ì´ìŠˆ**:
- `scan_source(deep_scan=True)`: Nê°œ í…Œì´ë¸” Ã— (ì¿¼ë¦¬ + í”„ë¡œíŒŒì¼ë§)
- ì˜ˆ: 50ê°œ í…Œì´ë¸” Ã— 1ì´ˆ = **50ì´ˆ ì´ìƒ!**

#### ğŸ“Œ table_recommender.py
```python
async def recommend_tables(self, intent: AnalysisIntent) -> List[TableRecommendation]
    # LLM í˜¸ì¶œ (API I/O)

async def infer_relationships(self, tables: List[str]) -> List[ERDRelationship]
    # LLM í˜¸ì¶œ (API I/O)
```

#### ğŸ“Œ sql_generator.py
```python
async def generate_sql(self, ...) -> str
    # LLM í˜¸ì¶œ (API I/O)

async def generate_sql_with_validation(self, ...) -> str
    # LLM í˜¸ì¶œ + ê²€ì¦

async def _generate_explanation(self, sql: str, user_query: str) -> str
    # LLM í˜¸ì¶œ
```

#### ğŸ“Œ pandas_generator.py
```python
async def generate_transform_code(self, ...) -> str
    # LLM í˜¸ì¶œ

async def _generate_explanation(self, code: str) -> str
    # LLM í˜¸ì¶œ
```

#### ğŸ“Œ query_healer.py
```python
async def diagnose_error(self, error_msg: str, ...) -> DiagnosisResult
    # LLM í˜¸ì¶œ

async def heal_and_retry(self, execute_fn: Callable[[str], Awaitable[Any]], ...) -> str
    # ì¬ì‹œë„ ë¡œì§ + LLM í˜¸ì¶œ
    # execute_fn: SQL ì‹¤í–‰ í•¨ìˆ˜ (async callable expected!)
```

#### ğŸ“Œ data_source_agent.py
```python
async def get_client(self, connection_info: Dict[str, Any]) -> MCPClient
async def query_database(self, connection_info: Dict[str, Any], user_query: str) -> pd.DataFrame
async def read_excel(self, file_path_or_info: Any, user_query: Optional[str] = None) -> pd.DataFrame
async def _analyze_dataframe_with_llm(self, df: pd.DataFrame, user_query: str) -> pd.DataFrame
async def close_all(self)
```

#### ğŸ“Œ mcp_client.py
```python
async def connect(self)
async def list_tools(self) -> List[Any]
async def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any
async def disconnect(self)
```

---

## 3. TUI ë©”ì¸ ì§„ì…ì 

### ğŸ“Œ bi_agent_console.py (Textual App)
**íŒŒì¼**: `/Users/zokr/python_workspace/BI-Agent/backend/orchestrator/bi_agent_console.py`

```python
class BI_AgentConsole(App):
    TITLE = "BI-Agent Console"
    CSS_PATH = ["ui/app_styles.tcss"]

    BINDINGS = [
        Binding("q", "quit", "Quit"),
        Binding("v", "show_visual_report", "Visual Report"),
        Binding("ctrl+l", "clear_chat", "Clear Chat"),
        Binding("slash", "focus_input_with_slash", "Command"),
        Binding("f1", "show_help", "Help"),
        Binding("ctrl+e", "show_errors", "Errors"),
    ]
```

#### ì£¼ìš” ë©”ì„œë“œ

**1. `on_mount()` - ì´ˆê¸°í™”**
```python
async def on_mount(self) -> None:
    auth_manager.load_credentials()

    # íƒ€ì´ë¨¸ë¡œ ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
    self.set_timer(0.1, self._update_sidebar_loop)
    self.set_timer(1, self._update_hud_loop)
```

**2. `_update_sidebar_loop()` - ì‚¬ì´ë“œë°” ì—…ë°ì´íŠ¸**
```python
async def _update_sidebar_loop(self) -> None:
    await self.sidebar_manager.update()
    self.set_timer(10, self._update_sidebar_loop)  # 10ì´ˆë§ˆë‹¤ ë°˜ë³µ
```

**3. `_update_hud_loop()` - HUD ìƒíƒœ ì—…ë°ì´íŠ¸**
```python
async def _update_hud_loop(self) -> None:
    hud = self.query_one("#hud-status", HUDStatusLine)
    # ëª¨ë¸ëª… í™•ì¸ (auth_manager ìƒíƒœ)
    for p, name in [("gemini", "Gemini"), ("claude", "Claude"), ("openai", "GPT-4o")]:
        if auth_manager.is_authenticated(p):
            model_name = name
            break
    hud.update_model(model_name)
    hud.update_context(20.0)
    self.set_timer(10, self._update_hud_loop)
```

**4. `on_input_submitted()` - ì…ë ¥ ì²˜ë¦¬**
```python
async def on_input_submitted(self, event: Input.Submitted) -> None:
    user_text = event.value.strip()

    # QuestionFlowEngine í™•ì¸
    if self.flow_engine.is_active():
        consumed = await self.flow_engine.handle_input(user_text)
        if consumed:
            return

    # ëª…ë ¹ì–´ vs ì¼ë°˜ ì¿¼ë¦¬
    if user_text.startswith("/"):
        await self.handle_command(user_text)
    else:
        await self.process_query(user_text)  # âš ï¸ ASYNC!
```

**5. `process_query()` - ì¿¼ë¦¬ ì²˜ë¦¬ (ReAct ë£¨í”„)**
```python
async def process_query(self, query: str) -> None:
    chat_log = self.query_one("#chat-log", VerticalScroll)

    # Thinking íŒ¨ë„ í‘œì‹œ
    thinking = ThinkingPanel()
    chat_log.mount(thinking)

    try:
        orchestrator = self._get_orchestrator()

        # âš ï¸ BLOCKING: ReAct ë£¨í”„ ì‹¤í–‰
        result = await orchestrator.run(query, context={
            "active_connection": getattr(self, '_active_conn_id', None),
        })

        thinking.remove()

        if result["status"] == "success":
            response = result["final_response"]
            iter_count = result.get("iteration_count", 0)
            if iter_count > 1:
                footer = f"\n[dim]({iter_count}íšŒ ë¶„ì„ ë‹¨ê³„)[/dim]"
                response += footer
            chat_log.mount(MessageBubble(role="assistant", content=response))
    except Exception as e:
        # ì—ëŸ¬ ì²˜ë¦¬
        pass
```

**6. `_run_explore()` - ë°ì´í„°ë² ì´ìŠ¤ íƒìƒ‰**
```python
async def _run_explore(self, query: Optional[str], mode: Optional[str] = None, ...):
    # DatabaseExplorerScreen í‘¸ì‹œ
    self.push_screen(DatabaseExplorerScreen(
        connection_id=conn_id,
        conn_mgr=self.conn_mgr,
        agent_conn_mgr=self.agent_conn_mgr,
        initial_query=query,
        mode=mode,
        provider=provider
    ))
```

### ğŸ“Œ main.py (êµ¬í˜• Entry Point)
**íŒŒì¼**: `/Users/zokr/python_workspace/BI-Agent/backend/main.py`

```python
async def interactive_loop():
    # ì´ˆê¸°í™”
    ui = InteractionUI()
    dashboard = DashboardView(console=console)
    quota_manager = QuotaManager()
    conn_manager = ConnectionManager()
    data_agent = DataSourceAgent()

    # GCP ë™ê¸°í™”
    if project_id:
        with console.status("[bold green]GCP í• ë‹¹ëŸ‰ ë™ê¸°í™” ì¤‘..."):
            await quota_manager.sync_with_gcp(project_id)  # âš ï¸ ASYNC I/O

    # LLM Provider ì„¤ì •
    gemini = GeminiProvider(quota_manager=quota_manager)
    ollama = OllamaProvider()
    llm = FailoverLLMProvider(primary=gemini, secondary=ollama)

    # ì¿¼ë¦¬ ë£¨í”„
    while True:
        user_input = Prompt.ask(...)  # âš ï¸ BLOCKING! (ì½˜ì†”)

        if user_input.startswith("/"):
            # ëª…ë ¹ì–´ ì²˜ë¦¬
            pass
        else:
            # ì¿¼ë¦¬ ì²˜ë¦¬
            with console.status("[bold yellow]ì‚¬ê³  ê³¼ì • (Chain of Thought)..."):
                result = await orchestrator.run(user_input, context=context)  # âš ï¸ ASYNC I/O
```

**ì§„ì…ì **:
```python
if __name__ == "__main__":
    asyncio.run(interactive_loop())
```

---

## 4. Blocking Call ë¶„ì„ ë° ì„±ëŠ¥ ì´ìŠˆ

### 4.1 DatabaseExplorerScreenì˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œ
**íŒŒì¼**: `/Users/zokr/python_workspace/BI-Agent/backend/orchestrator/screens/database_explorer_screen.py`

#### âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²• - run_in_executor ì‚¬ìš©

```python
async def _load_schema(self):
    """Loads tables/views from the connection manager asynchronously."""
    tree = self.query_one("#schema-tree")

    # ë¡œë”© ì¸ë””ì¼€ì´í„° í‘œì‹œ
    loading_node = tree.root.add("ğŸ“¡ Loading schema...", expand=True)

    try:
        # âœ… ìŠ¤ë ˆë“œ í’€ì—ì„œ ë¸”ë¡œí‚¹ ì‘ì—… ì‹¤í–‰
        def _scan_metadata():
            scanner = MetadataScanner(self.agent_conn_mgr)
            return scanner.scan_source(self.connection_id, deep_scan=False)

        loop = asyncio.get_event_loop()
        metadata = await loop.run_in_executor(None, _scan_metadata)  # âœ… GOOD!

        # ê²°ê³¼ ì²˜ë¦¬ (UI ìŠ¤ë ˆë“œ)
        tree.root.remove_children()
        tables_node = tree.root.add("ğŸ“Š Tables", expand=True)

        for table_info in metadata.get("tables", []):
            table_name = table_info.get("table_name", "unknown")
            tables_node.add_leaf(f"  {table_name}")

    except Exception as e:
        logger.error(f"Failed to load schema: {e}")
        # ì—ëŸ¬ í‘œì‹œ
```

#### âœ… ì¿¼ë¦¬ ì‹¤í–‰ - run_in_executor ì‚¬ìš©

```python
async def _execute_query(self) -> None:
    """Run the SQL query against the actual database connection."""
    query = self.query_one("#sql-editor", VimTextArea).text.strip()

    status_label = self.query_one("#results-status", Label)
    status_label.update("[bold yellow]â³ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...[/bold yellow]")

    try:
        start_time = time.time()

        # âœ… ë¸”ë¡œí‚¹ DB ì¿¼ë¦¬ë¥¼ ìŠ¤ë ˆë“œ í’€ì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        df = await loop.run_in_executor(
            None,
            lambda: self.agent_conn_mgr.run_query(self.connection_id, query)
        )

        execution_time_ms = (time.time() - start_time) * 1000

        # UI ì—…ë°ì´íŠ¸
        self._render_dataframe(df)
        row_count = len(df)
        col_count = len(df.columns)
        status_label.update(f"[bold green]âœ“ {row_count} rows Ã— {col_count} columns[/bold green]")

        # íˆìŠ¤í† ë¦¬ì— ì €ì¥
        history_entry = QueryHistoryEntry(
            query=query,
            timestamp=datetime.now().isoformat(),
            connection_id=self.connection_id,
            execution_time_ms=execution_time_ms,
            row_count=row_count,
            status="success",
            error_message=None
        )
        self.query_history.add_entry(history_entry)

    except Exception as e:
        logger.error(f"Query execution failed: {e}")
        status_label.update(f"[bold red]âœ— Error: {str(e)}[/bold red]")
    finally:
        self._query_running = False
```

---

### 4.2 AgenticOrchestratorì˜ ReAct ë£¨í”„
**íŒŒì¼**: `/Users/zokr/python_workspace/BI-Agent/backend/orchestrator/orchestrators/agentic_orchestrator.py`

#### âš ï¸ BLOCKING CALLS (ë„êµ¬ ì‹¤í–‰ í•¨ìˆ˜)

```python
def _build_default_registry() -> ToolRegistry:
    """ê¸°ë³¸ ë„êµ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ - ìˆ˜ë™ Tool Calling"""

    # âš ï¸ 1. query_database() - ë¸”ë¡œí‚¹ SQLite ì¿¼ë¦¬
    def query_database(query_description: str = "") -> str:
        # ... ì¿¼ë¦¬ íŒŒì‹± ...
        try:
            conn = sqlite3.connect(db_path)  # âš ï¸ I/O
            conn.row_factory = sqlite3.Row
            cur = conn.cursor()
            cur.execute(query)  # âš ï¸ BLOCKING!
            rows = cur.fetchall()  # âš ï¸ I/O
            conn.close()
            # ê²°ê³¼ í¬ë§·íŒ…
            return result_str
        except Exception as e:
            return f"ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}"

    # âš ï¸ 2. analyze_schema() - ë¸”ë¡œí‚¹ PRAGMA ì¿¼ë¦¬
    def analyze_schema(table_name: str = "") -> str:
        try:
            conn = sqlite3.connect(db_path)
            cur = conn.cursor()

            # í…Œì´ë¸” ëª©ë¡
            tables = cur.execute(
                "SELECT name FROM sqlite_master WHERE type='table'"
            ).fetchall()  # âš ï¸ BLOCKING!

            for tbl in targets:
                # ì»¬ëŸ¼ ì •ë³´
                cols = cur.execute(f'PRAGMA table_info("{tbl}")').fetchall()  # âš ï¸ BLOCKING!

                # í–‰ ê°œìˆ˜
                count = cur.execute(f'SELECT COUNT(*) FROM "{tbl}"').fetchone()[0]  # âš ï¸ BLOCKING!

                # ìœ ë‹ˆí¬ ê°’
                unique = cur.execute(
                    f'SELECT COUNT(DISTINCT "{col_name}") FROM "{tbl}"'
                ).fetchone()[0]  # âš ï¸ BLOCKING!
```

#### ë¬¸ì œì 

| ë„êµ¬ | ì‘ì—… | íŠ¹ì„± | ì˜ˆìƒ ì‹œê°„ |
|------|------|------|---------|
| `query_database()` | SQLite ì¿¼ë¦¬ | BLOCKING | 100ms-10s |
| `analyze_schema()` | í…Œì´ë¸” ë¶„ì„ + PRAGMA | BLOCKING | 500ms-5s |
| `recommend_chart()` | ChartRecommender | ë™ê¸° í˜¸ì¶œ | 50-200ms |
| `generate_chart()` | ChartRecommender | ë™ê¸° í˜¸ì¶œ | 50-200ms |
| `apply_theme()` | ThemeEngine | ë™ê¸° í˜¸ì¶œ | 10-50ms |
| `calculate_layout()` | LayoutCalculator | ë™ê¸° í˜¸ì¶œ | 10-50ms |
| `setup_interactions()` | InteractionLogic | ë™ê¸° í˜¸ì¶œ | 20-100ms |

**âš ï¸ í•µì‹¬ ë³‘ëª©**:
- `query_database()` + `analyze_schema()`: **ReAct ë£¨í”„ì—ì„œ ê°€ì¥ ëŠë¦° ì‘ì—…**
- ì´ë“¤ì€ `run_in_executor`ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ!
- **UI í”„ë¦¬ì§• ìœ„í—˜**

---

### 4.3 MetadataScannerì˜ ê¹Šì€ ìŠ¤ìº”
**íŒŒì¼**: `/Users/zokr/python_workspace/BI-Agent/backend/agents/data_source/metadata_scanner.py`

```python
def scan_source(self, conn_id: str, deep_scan: bool = False) -> Dict[str, Any]:
    """Scans the source."""
    conn_info = self._get_conn_info(conn_id)
    conn_type = conn_info["type"]

    metadata = {
        "conn_id": conn_id,
        "type": conn_type,
        "tables": []
    }

    table_names = self._list_tables(conn_id, conn_type)  # âš ï¸ BLOCKING!

    for table in table_names:
        if deep_scan:
            table_meta = self.scan_table(conn_id, table)  # âš ï¸ BLOCKING! Në²ˆ ë°˜ë³µ
        else:
            table_meta = {"table_name": table, "is_lazy": True}
        metadata["tables"].append(table_meta)

    return metadata

def scan_table(self, conn_id: str, table_name: str) -> Dict[str, Any]:
    """Performs detailed profiling of a single table."""
    # 1. ìƒ˜í”Œ ë°ì´í„° í˜ì¹˜
    safe_table_name = table_name.replace('"', '""')
    query = f'SELECT * FROM "{safe_table_name}" LIMIT 100'
    df = self.conn_mgr.run_query(conn_id, query)  # âš ï¸ BLOCKING!

    # 2. DataProfiler ì‹¤í–‰
    profiler = DataProfiler(df)
    profile_data = profiler.profile()  # âš ï¸ BLOCKING! (1-2ì´ˆ)

    return {
        "table_name": table_name,
        "row_count_estimate": profile_data["overview"]["rows"],
        "columns": profile_data["columns"],
        "sample": profile_data["sample"]
    }
```

**ì„±ëŠ¥ ê³„ì‚°**:
- 50ê°œ í…Œì´ë¸” Ã— `deep_scan=True`:
  - ê° í…Œì´ë¸”: SELECT LIMIT 100 (~100ms) + profile() (~1s) = ~1.1s
  - **ì´: 50 Ã— 1.1s = 55ì´ˆ!** âš ï¸

---

## 5. ì„±ëŠ¥ ìµœì í™” ê¶Œì¥ì‚¬í•­

### ğŸ¯ ìš°ì„ ìˆœìœ„ 1: ë†’ìŒ (ê¸´ê¸‰)

#### 1.1 MetadataScannerë¥¼ ë¹„ë™ê¸°ë¡œ ë¦¬íŒ©í† ë§

```python
# í˜„ì¬ (ë™ê¸°)
def scan_source(self, conn_id: str, deep_scan: bool = False):
    table_names = self._list_tables(conn_id, conn_type)
    for table in table_names:
        table_meta = self.scan_table(conn_id, table)  # ìˆœì°¨ ì‹¤í–‰

# ê°œì„ ì•ˆ (ë¹„ë™ê¸° ë³‘ë ¬)
async def scan_source(self, conn_id: str, deep_scan: bool = False):
    table_names = self._list_tables(conn_id, conn_type)

    if deep_scan:
        # ë³‘ë ¬ ìŠ¤ìº” (ìµœëŒ€ 5-10ê°œ ë™ì‹œ ì‘ì—…)
        tasks = [
            self._scan_table_async(conn_id, table)
            for table in table_names[:10]  # ì œí•œ
        ]
        results = await asyncio.gather(*tasks)
        metadata["tables"] = results
    else:
        # Lazy ë¡œë“œ
        metadata["tables"] = [
            {"table_name": t, "is_lazy": True}
            for t in table_names
        ]
```

**ê¸°ëŒ€ íš¨ê³¼**:
- 50ê°œ í…Œì´ë¸”, 5ê°œ ë™ì‹œ: 55ì´ˆ â†’ 11ì´ˆ (5ë°° ê°œì„ )
- íŠ¹ì • í…Œì´ë¸”ë§Œ ìƒì„¸ ìŠ¤ìº”: ì´ˆë‹¨ìœ„ ì‘ë‹µ

#### 1.2 profiler.pyë¥¼ ë¹„ë™ê¸°ë¡œ ë¦¬íŒ©í† ë§

```python
# í˜„ì¬ (ë™ê¸°, ëŒ€ìš©ëŸ‰ì—ì„œ ëŠë¦¼)
profile_data = profiler.profile()  # 1-2ì´ˆ (1Mí–‰)

# ê°œì„ ì•ˆ (ìŠ¤ë ˆë“œ í’€ + asyncio)
async def profile_async(self) -> Dict[str, Any]:
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(None, self.profile)
```

**ê¸°ëŒ€ íš¨ê³¼**:
- UIê°€ ë¸”ë¡œí‚¹ë˜ì§€ ì•ŠìŒ
- ì‚¬ìš©ìëŠ” ê³„ì† ì…ë ¥ ê°€ëŠ¥

#### 1.3 ToolRegistryì˜ ì¿¼ë¦¬ ë„êµ¬ë¥¼ ë¹„ë™ê¸°ë¡œ ë³€ê²½

```python
# í˜„ì¬ (ë™ê¸°)
def query_database(query_description: str = "") -> str:
    conn = sqlite3.connect(db_path)
    cur.execute(query)  # BLOCKING

# ê°œì„ ì•ˆ (async ì§€ì›)
async def query_database_async(query_description: str = "") -> str:
    loop = asyncio.get_event_loop()
    def _execute():
        conn = sqlite3.connect(db_path)
        cur = conn.cursor()
        cur.execute(query)
        return cur.fetchall()

    rows = await loop.run_in_executor(None, _execute)
    # ê²°ê³¼ í¬ë§·íŒ…
    return result_str
```

**ë¬¸ì œ**:
- ToolRegistry.execute()ëŠ” ë™ê¸° í•¨ìˆ˜
- ReAct ë£¨í”„ê°€ ì´ë¥¼ awaití•  ìˆ˜ ì—†ìŒ
- **í•´ê²°ì±…**: LangGraph ë…¸ë“œë¥¼ ë¹„ë™ê¸°ë¡œ ë³€ê²½

---

### ğŸ¯ ìš°ì„ ìˆœìœ„ 2: ì¤‘ê°„

#### 2.1 ConnectionManager.run_query()ë¥¼ ë¹„ë™ê¸°ë¡œ ë˜í•‘

```python
# /backend/agents/data_source/connection_manager_async.py (ì‹ ê·œ)
class AsyncConnectionManager:
    def __init__(self, sync_cm: ConnectionManager):
        self.sync_cm = sync_cm

    async def run_query_async(self, conn_id: str, query: str) -> pd.DataFrame:
        """Runs query in thread pool, non-blocking."""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            None,
            lambda: self.sync_cm.run_query(conn_id, query)
        )
```

**ì‚¬ìš©ì²˜**:
- MetadataScanner: `self.conn_mgr.run_query()` â†’ `self.async_cm.run_query_async()`
- DatabaseExplorerScreen: ì´ë¯¸ ì ìš©ë¨ âœ…

#### 2.2 DatabaseExplorerScreenì˜ ìŠ¤í‚¤ë§ˆ ë¡œë“œì— íƒ€ì„ì•„ì›ƒ ì¶”ê°€

```python
async def _load_schema(self):
    try:
        def _scan_metadata():
            scanner = MetadataScanner(self.agent_conn_mgr)
            return scanner.scan_source(self.connection_id, deep_scan=False)

        loop = asyncio.get_event_loop()
        # íƒ€ì„ì•„ì›ƒ 30ì´ˆ (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
        metadata = await asyncio.wait_for(
            loop.run_in_executor(None, _scan_metadata),
            timeout=30.0
        )
    except asyncio.TimeoutError:
        logger.error("Schema load timed out after 30 seconds")
        self.notify("Schema load timed out. Showing table list only.", severity="warning")
```

#### 2.3 HUD ë° ì‚¬ì´ë“œë°” ì—…ë°ì´íŠ¸ ìµœì í™”

```python
# í˜„ì¬: ë§¤ 0.1ì´ˆë§ˆë‹¤ (ê³¼í•˜ê²Œ ë¹ˆë²ˆ)
self.set_timer(0.1, self._update_sidebar_loop)

# ê°œì„ : 1-2ì´ˆë§ˆë‹¤ (í•„ìš”í•œ ì¶©ë¶„í•¨)
self.set_timer(1.0, self._update_sidebar_loop)
```

**ê¸°ëŒ€ íš¨ê³¼**:
- CPU ì‚¬ìš©ë¥  ê°ì†Œ
- ë°°í„°ë¦¬ ì†Œë¹„ ê°ì†Œ

---

### ğŸ¯ ìš°ì„ ìˆœìœ„ 3: ë‚®ìŒ (ë¯¸ë˜)

#### 3.1 ë°ì´í„° í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ìºì‹±

```python
# /backend/agents/data_source/profiler_cache.py (ì‹ ê·œ)
class ProfileCache:
    def __init__(self, ttl_seconds: int = 300):
        self.cache = {}
        self.ttl = ttl_seconds

    def get(self, conn_id: str, table_name: str) -> Optional[Dict]:
        key = f"{conn_id}:{table_name}"
        if key in self.cache:
            cached_time, data = self.cache[key]
            if time.time() - cached_time < self.ttl:
                return data
            del self.cache[key]
        return None

    def set(self, conn_id: str, table_name: str, data: Dict):
        key = f"{conn_id}:{table_name}"
        self.cache[key] = (time.time(), data)
```

**ì‚¬ìš©ì²˜**:
```python
class MetadataScanner:
    def __init__(self, connection_manager: ConnectionManager, cache: Optional[ProfileCache] = None):
        self.conn_mgr = connection_manager
        self.cache = cache or ProfileCache()

    def scan_table(self, conn_id: str, table_name: str) -> Dict[str, Any]:
        # ìºì‹œ í™•ì¸
        cached = self.cache.get(conn_id, table_name)
        if cached:
            return cached

        # ... í”„ë¡œíŒŒì¼ë§ ...
        self.cache.set(conn_id, table_name, result)
        return result
```

#### 3.2 ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤í–‰

```python
# ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ í•œ ë²ˆì— ì‹¤í–‰ (ë„¤íŠ¸ì›Œí¬ ì™•ë³µ ê°ì†Œ)
async def run_queries_batch(self, conn_id: str, queries: List[str]):
    """Execute multiple queries in parallel."""
    loop = asyncio.get_event_loop()
    tasks = [
        loop.run_in_executor(
            None,
            lambda q=q: self.sync_cm.run_query(conn_id, q)
        )
        for q in queries
    ]
    return await asyncio.gather(*tasks)
```

#### 3.3 ìŠ¤íŠ¸ë¦¬ë° ê²°ê³¼ (ëŒ€ìš©ëŸ‰ ë°ì´í„°)

```python
async def run_query_streaming(self, conn_id: str, query: str, batch_size: int = 1000):
    """Stream query results in batches."""
    loop = asyncio.get_event_loop()

    def _fetch_batches():
        # DB ì»¤ì„œë¡œ batch ë‹¨ìœ„ë¡œ ì½ê¸°
        for batch_df in pd.read_sql_query(query, conn, chunksize=batch_size):
            yield batch_df

    for batch in await loop.run_in_executor(None, _fetch_batches):
        yield batch
        await asyncio.sleep(0)  # ë‹¤ë¥¸ ì‘ì—…ì— CPU ì–‘ë³´
```

---

## ğŸ“Š ì„±ëŠ¥ ê°œì„  ì˜ˆìƒì¹˜

### Before (í˜„ì¬ ìƒíƒœ)

| ì‹œë‚˜ë¦¬ì˜¤ | ì†Œìš” ì‹œê°„ | UI ìƒíƒœ |
|---------|---------|--------|
| 50ê°œ í…Œì´ë¸” ìŠ¤ìº” (deep) | 55ì´ˆ | ğŸ”´ ì™„ì „ í”„ë¦¬ì§• |
| ë‹¨ì¼ ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ (1Mí–‰) | 5-10ì´ˆ | ğŸ”´ í”„ë¦¬ì§• |
| í”„ë¡œíŒŒì¼ë§ (1Mí–‰Ã—50ì»¬ëŸ¼) | 2ì´ˆ | ğŸ”´ í”„ë¦¬ì§• |

### After (ìš°ì„ ìˆœìœ„ 1 ì ìš© í›„)

| ì‹œë‚˜ë¦¬ì˜¤ | ì†Œìš” ì‹œê°„ | UI ìƒíƒœ |
|---------|---------|--------|
| 50ê°œ í…Œì´ë¸” ìŠ¤ìº” (5ë³‘ë ¬) | 11ì´ˆ | ğŸŸ¡ ë°˜ì‘ ê°€ëŠ¥ |
| ë‹¨ì¼ ëŒ€ìš©ëŸ‰ ì¿¼ë¦¬ | 5-10ì´ˆ | ğŸŸ¢ ë°˜ì‘ ê°€ëŠ¥ |
| í”„ë¡œíŒŒì¼ë§ | 2ì´ˆ | ğŸŸ¢ ë°˜ì‘ ê°€ëŠ¥ |

**ê°œì„  íš¨ê³¼**:
- 50ê°œ í…Œì´ë¸” ìŠ¤ìº”: **55s â†’ 11s (5ë°° ê°œì„ )**
- UI ë°˜ì‘ì„±: **ì¦‰ê°ì ** (run_in_executor ë•ë¶„)
- ì‚¬ìš©ì ê²½í—˜: **ìš°ìˆ˜**

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¹„ë™ê¸° ë¦¬íŒ©í† ë§

- [ ] MetadataScanner.scan_source() â†’ async ë²„ì „ ì¶”ê°€
- [ ] MetadataScanner.scan_table() â†’ async ë²„ì „ ì¶”ê°€
- [ ] DataProfiler.profile() â†’ executor ë˜í•‘ ì¶”ê°€
- [ ] AgenticOrchestrator ë„êµ¬ â†’ async ë²„ì „ìœ¼ë¡œ ë³€ê²½
- [ ] ConnectionManager.run_query() â†’ async ë˜í¼ ì¶”ê°€
- [ ] DatabaseExplorerScreen._load_schema() â†’ íƒ€ì„ì•„ì›ƒ ì¶”ê°€

### ì„±ëŠ¥ ìµœì í™”

- [ ] í”„ë¡œíŒŒì¼ ê²°ê³¼ ìºì‹± êµ¬í˜„
- [ ] HUD ì—…ë°ì´íŠ¸ ê°„ê²© ì¡°ì • (0.1s â†’ 1s)
- [ ] ë°°ì¹˜ ì¿¼ë¦¬ ì‹¤í–‰ ì§€ì›
- [ ] ëŒ€ìš©ëŸ‰ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° ì§€ì›

### ëª¨ë‹ˆí„°ë§

- [ ] ì„±ëŠ¥ ë¡œê¹… ì¶”ê°€ (ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„)
- [ ] AsyncIO ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™” (ê°œë°œ ë‹¨ê³„)
- [ ] UI ì‘ë‹µ ì‹œê°„ ì¸¡ì •

---

## ğŸ“š ì°¸ê³  ìë£Œ

### AsyncIO íŒ¨í„´
- `asyncio.run_in_executor()`: ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ë˜í•‘
- `asyncio.gather()`: ì—¬ëŸ¬ ì½”ë£¨í‹´ ë³‘ë ¬ ì‹¤í–‰
- `asyncio.wait_for()`: íƒ€ì„ì•„ì›ƒ ì§€ì›

### Textual í”„ë ˆì„ì›Œí¬
- `asyncio.create_task()`: ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
- `set_timer()`: ì£¼ê¸°ì  ì‘ì—…
- Screen/Appì˜ async ë©”ì„œë“œë“¤

### ë°ì´í„° ì²˜ë¦¬
- `pd.read_sql_query()`: SQL ì¿¼ë¦¬ â†’ DataFrame
- `pd.read_sql()` with chunksize: ìŠ¤íŠ¸ë¦¬ë° ì½ê¸°
- `numpy.histogram()`: ë¶„í¬ ê³„ì‚°

